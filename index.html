<!doctype html>
<html lang="en">
<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta http-equiv=“Pragma” content=”no-cache”>
  <meta http-equiv=“Expires” content=”-1″>
  <meta http-equiv=“CACHE-CONTROL” content=”NO-CACHE”>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

  <!-- Negative Momentum -->
  <link rel="stylesheet" type="text/css" href="css/eigenvalues.css">
  <link rel="stylesheet"  type="text/css" href="css/colors.css">
  <link rel="stylesheet" type="text/css" href="main.css">
  <link rel="icon"
  type="image/png"
  href="img/favico.png">

  <title>Gabriel Huang</title>
</head>
<body>

  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="js/jquery-3.5.1.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

  <div style="text-align:center; margin: 3em auto;">
    <div style="display: inline-block; margin-bottom: 2em;">
      <div style="width: 300px; float: left; margin: 20px 0; clear: right; ">
        <p class="lead">Gabriel Huang</p>
        <p>PhD candidate<br> Mila &amp; University of Montreal<br>
          Part-time research intern at ServiceNow ElementAI</p>
      </div>
      <img src="id-flower.jpg" width="160" height="160" style="border-radius: 50%;" alt="gabriel huang profile picture" style="float: left; margin: 0 20px;">
    </div>
  </div>


      <div class="container" >

        <div style="display: inline-block;" class="btn-group" role="group" aria-label="Basic example">
          <a class="btn btn-success" href="#publications" role="button">Publications</a>
          <a class="btn btn-info" href="#thin" role="button">Thin-8</a>
          <a class="btn btn-primary" href="https://scholar.google.com/citations?user=_X1Tl-MAAAAJ" role="button">Scholar</a>
          <a class="btn btn-danger" href="https://github.com/gabrielhuang/" role="button">Github</a>
          <a class="btn btn-warning" href="./cv.pdf" role="button">CV</a>
        </div>
        <br><br>

        <p>
          Gabriel Huang is a PhD candidate
          at <a href="https://mila.quebec/en/">Mila</a> &amp;
          <a href="https://www.umontreal.ca/en/">University of Montreal</a> under the supervision of <a href="http://www.iro.umontreal.ca/~slacoste/">Simon Lacoste-Julien</a>.
          He is interested in generative learning, latent-variable models,
          structured prediction, optimal transport, weakly-supervised learning,
          reinforcement learning, convex optimization, music generation,
          and fundamental questions of optimization and statistical learning.

          Previously he did the <a href="http://www.math.ens-cachan.fr/version-francaise/formations/master-mva/contenus-/master-mva-cours-2016-2017-161721.kjsp?RH=1242430202531">MVA Master's degree</a>
          in machine learning at  École Normale Supérieure in Paris,
          in parallel with an engineer's degree at CentraleSupélec,
          one of the top engineering schools in France.
          While he was doing his master's, I also worked as a part-time research apprentice on
          human activity recognition using RGB-D cameras and on recommender systems.
        </p>


        <!-- Negative momentum -->
        <script src="https://d3js.org/d3.v5.min.js"></script>
        <script src="js/math.min.js"></script>
        <script src="js/eigenvalues.js"></script>
        <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

        <h4> <a name="negative_momentum_visualization">Negative Momentum</a> </h4>

        <p>Below is an interactive visualization of our paper <a href="#negative_momentum_paper">Negative Momentum for Improved Game Dynamics</a>:<br>
          (a) Learning rate (<b>lr</b>) and momentum (<b>beta</b>) hyperparameters.<br>
          (b) Resulting eigenvalues in the complex plane for <u class="sgd">SGD</u> and <u class="sgdmomentum">SGD+momentum</u>. </p>
          <p>There is convergence if and only if all eigenvalues are inside the convergence ball (green). <br>Try to find the hyperparameters for convergence.</p>

          <div style="text-align:center">
            <div style="text-align:center; display:inline-block">
              <svg class="touchpad">
                <p>(a) Hyperparameters.
                </svg>
              </div>
              <div style="text-align:center; display:inline-block;">
                <svg class="chart">
                  <p>(b) Eigenvalues in complex plane.
                  </svg>
                </div>


              </div>

              <h5></h5>


              <p><u class="sgd">SGD without momentum:</u> using <span class="snm-span p_lr b"></span>,
                eigenvalues are <span class="p_sgd_inside b"></span> the convergence ball &rarr;  <span class="b p_sgd_converges"></span><br>

                <u class="sgdmomentum">SGD with momentum:</u> using <span class="snm-span p_lr b"></span>
                and <span class="p_sign_beta b"></span> momentum <span class="p_beta b"></span>,
                eigenvalues are <span class="p_momentum_inside b"></span> the convergence ball &rarr; <span class="b p_momentum_converges"></span> </p>


                <h4> <a name="publications">Publications and preprints</a> </h4>

                <script>
                $(document).ready(function(){
                  on_resize();
                })

                $(window).resize(function(){
                  on_resize();
                });

                function on_resize() {
                  if ($('.papers').width() < 600) {
                    // image on top
                    $('.papers .img').css('float', 'none');
                    $('.papers .text').css('width', '100%');
                  } else {
                    // side by side
                    $('.papers .img').css('float', 'left');
                    $('.papers .text').css('width', ($('.papers').width() - 250) + 'px');
                  }
                }
                </script>

                  <div class="papers">
                    <div>
                      <div class="img">
                        <img src="img/fsod.jpg">
                      </div>
                      <div class="text">
                        <span class="badge badge-secondary">arxiv</span>
                        <span class="pt"><a href="https://gabrielhuang.github.io/fsod-survey/">A Survey of Self-Supervised and Few-Shot Object Detection</a></span> <br>
                        Gabriel Huang, Issam Laradji, David Vazquez, Simon Lacoste-Julien, Pau Rodriguez<br>
                        Submitted to IEEE TPAMI.<br>
                        <div class="btn-group">
                          <a class="btn btn-outline-secondary btn-sm" href="https://arxiv.org/abs/2110.14711" role="button">arXiv</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://gabrielhuang.github.io/fsod-survey/" role="button">project page</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://twitter.com/GabrielHuang9/status/1455639917497827334" role="button">tweetorial</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://github.com/gabrielhuang/awesome-few-shot-object-detection" role="button">Awesome-FSOD</a>
                         </div>
                      </div>
                    </div>
                    <div>
                      <div class="img">
                        <img src="img/repurposing.png">
                      </div>
                      <div class="text">
                        <span class="badge badge-success">paper</span>
                        <span class="pt"><a href="https://arxiv.org/pdf/2103.09027.pdf">Repurposing Pretrained Models for Robust Out-of-domain Few-Shot Learning</a>
                        </span> <br>
                        Namyeong Kwon, Hwidong Na, Gabriel Huang, Simon Lacoste-Julien<br>
                        ICLR'21 paper.<br>
                        <div class="btn-group" >
                          <a class="btn btn-outline-secondary btn-sm" href="https://arxiv.org/abs/2103.09027" role="button">arXiv</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://arxiv.org/pdf/2103.09027.pdf" role="button">pdf</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://openreview.net/forum?id=qkLMTphG5-h" role="button">openreview</a>
                        </div>
                      </div>
                    </div>
                    <div>
                      <a name="multimodal-pretraining-paper"></a>
                      <div class="img">
                        <img src="img/multimodal-pretraining.png">
                      </div>
                      <div class="text">
                        <span class="badge badge-success">paper</span>
                        <span class="pt"><a href="https://arxiv.org/pdf/2011.11760.pdf">Multimodal Pretraining for Dense Video Captioning</a></span> <br>
                        Gabriel Huang, Bo Pang, Zhenhai Zhu, Clara Rivera, Radu Soricut<br>
                        <i>Introduces the Video Timeline Tags dataset (<a href="https://github.com/google-research-datasets/Video-Timeline-Tags-ViTT">ViTT</a>).</i> <br>
                        AACL-IJCNLP 2020.<br>
                        <div class="btn-group">
                          <a class="btn btn-outline-secondary btn-sm" href="https://arxiv.org/abs/2011.11760" role="button">arXiv</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://github.com/google-research-datasets/Video-Timeline-Tags-ViTT" role="button">dataset</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://youtu.be/hKSDJSDRee8" role="button">video</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://docs.google.com/presentation/d/13xu7UxdRHawI2lmgb8YF74SJ-g5VWtTF7mo5LqBwOv0/edit?usp=sharing" role="button">slides</a>
                        </div>
                      </div>
                    </div>
                    <div>
                      <div class="img">
                        <img src="img/centroid.jpg">
                      </div>
                      <div class="text">
                        <span class="badge badge-secondary">arXiv</span>
                        <span class="pt"><a href="https://arxiv.org/pdf/1902.08605.pdf">Are Few-Shot Learning Benchmarks too Simple ? Solving them without Task Supervision at Test-Time</a>
                        </span> <br>
                        This paper introduces <i>Centroid Networks</i> for Few-shot Clustering and Unsupervised Few-shot Classification<br>
                        Gabriel Huang, Hugo Larochelle, Simon Lacoste-Julien<br>
                        ICLR'19 workshop.<br>
                        <div class="btn-group" >
                          <a class="btn btn-outline-secondary btn-sm" href="https://arxiv.org/abs/1902.08605" role="button">arXiv</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://arxiv.org/pdf/1902.08605.pdf" role="button">pdf</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://github.com/gabrielhuang/centroid-networks" role="button">code</a>
                        </div>
                      </div>
                    </div>
                    <div>
                      <div class="img">
                        <img src="img/negative-momentum.jpg">
                      </div>
                      <div class="text">
                        <span class="badge badge-success">paper</span>
                        <span class="pt"><a name="negative_momentum_paper"><a href="https://arxiv.org/pdf/1807.04740.pdf">Negative Momentum for Improved Game Dynamics</a></a></span> <br>
                        Gauthier Gidel, Reyhane Askari Hemmat, Mohammad Pezeshki, Gabriel Huang, Rémi Lepriol, Simon Lacoste-Julien, Ioannis Mitliagkas.<br>
                        AISTATS 2019<br>
                        <div class="btn-group" >
                          <a class="btn btn-outline-secondary btn-sm" href="https://arxiv.org/abs/1807.04740" role="button">arXiv</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://gauthiergidel.github.io/slides/TTIC2018.pdf" role="button">slides</a>
                          <a class="btn btn-outline-secondary btn-sm" href="#negative_momentum_visualization" role="button">visualization</a>
                        </div>
                      </div>
                    </div>
                    <div>
                      <div class="img">
                        <img src="img/parametric.jpg">
                      </div>
                      <div class="text">
                        <span class="badge badge-secondary">arXiv</span>
                        <span class="pt"><a href="https://arxiv.org/pdf/1708.02511.pdf">Parametric Adversarial Divergences are Good Task Losses for Generative Modeling</a></span> <br>
                        Gabriel Huang, Hugo Berard, Ahmed Touati, Gauthier Gidel, Pascal Vincent, Simon Lacoste-Julien. <br>
                        ICML'17 Workshop, ICLR'18 Workshop, Montreal AI Symposium 2018, Submitted to JMLR<br>
                        <div class="btn-group" >
                          <a class="btn btn-outline-secondary btn-sm" href="https://arxiv.org/abs/1708.02511" role="button">arxiv</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://arxiv.org/pdf/1708.02511.pdf" role="button">pdf</a>
                          <a class="btn btn-outline-secondary btn-sm" href="https://openreview.net/forum?id=rkEtzzWAb&noteId=BkiY4k6rM" role="button">openreview</a>
                        </div>
                      </div>
                    </div>
                    <div>
                      <div class="img">
                        <img src="img/scattering.jpg">
                      </div>
                      <div class="text">
                        <span class="badge badge-success">paper</span>
                        <span class="pt"><a href="https://hal.inria.fr/hal-01837587/file/main.pdf">Scattering Networks for Hybrid Representation Learning</a></span> <br>
                        Edouard Oyallon, Sergey Zagoruyko, Gabriel Huang, Nikos Komodakis,
                        Simon Lacoste-Julien, Matthew Blaschko, Eugene Belilovsky.<br>
                        IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2018<br>
                        <div class="btn-group" >
                          <a class="btn btn-outline-secondary btn-sm" href="https://hal.inria.fr/hal-01837587/file/main.pdf">paper</a>
                        </div>
                      </div>
                    </div>
                  </div>


                <h4><a name="thin">Thin-8 dataset</a></h4>

                <p>The Thin-8 dataset consists of <b>1585</b> grayscale handwritten images of the digit 8, with resolution 512x512.<br>
                  16 people were asked to draw the digit 8 about 100 times using a pen on a tablet PC running Microsoft Windows.<br>
                  It was collected in October 2017 at the University of Montreal.<br>
                  <a href="https://drive.google.com/file/d/1TTgBm2eepo4vGU8UlGa6SbhvXoADArPP/view">Download Thin-8 dataset here</a></p>

                  <img src="img/thin-8.jpg" width="80%" style="margin: 1em;">

                  <p>If you use the Thin-8 dataset, please cite <a href="https://arxiv.org/abs/1708.02511">our paper </a>:</p>

                  <pre><code>@article{huang2018parametric,
                    title={Parametric Adversarial Divergences are Good Task Losses for Generative Modeling},
                    author={Huang, Gabriel and Berard, Hugo and Touati, Ahmed and Gidel, Gauthier and Vincent, Pascal and Lacoste-Julien, Simon},
                    journal={arXiv preprint arXiv:1708.02511},
                    year={2017}
                  }</code></pre>

                  <p>Thanks to Alex, Akram, Aristide, David, Dendi, Eugene,
                    Jae, Joao, Liam, Rémi, Rosemary, Shawn, Sina, and Xing for scribbling all those samples!</p>

                    <h4>Contact</h4>

                    <p>Email: <a href="mailto:gabriel.huang@umontreal.ca">gabriel.huang@umontreal.ca</a><br>
                      In person: Mila, 6666 St-Urbain, #200, Montreal, QC, H2S 3H1, Canada
                    </p>

                  </div>






                </body>
                </html>
